{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `photoeccentric` sensitivitiy tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook sets up a sensitivity test for `photoeccentric` to determine how accurately it recovers eccentricity with simulated transits. In general, this is also how I would structure the code to recover eccentricities for a large number of planets in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "\n",
    "# Using `batman` to create & fit fake transit\n",
    "import batman\n",
    "\n",
    "# Using astropy BLS and scipy curve_fit to fit transit\n",
    "from astropy.timeseries import BoxLeastSquares\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import scipy.optimize as opt\n",
    "\n",
    "# Using emcee & corner to find and plot (e, w) distribution\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "# And importing `photoeccentric`\n",
    "import photoeccentric as ph\n",
    "\n",
    "# Random stuff\n",
    "import scipy.constants as c\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll fit the transits with `emcee`, which takes a number of walkers, steps, and steps to discard. I'm defining them here so I can create my planet parameter distributions (period, rp/rs, a/rs, inclination) to be the proper length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalk = 64\n",
    "nsteps_d = 3000\n",
    "ndiscard_d = 1000\n",
    "arrlen = (nsteps_d-ndiscard_d)*nwalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "smass_kg = 1.9885e30  # Solar mass (kg)\n",
    "srad_m = 696.34e6 # Solar radius (m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run with Kepler light curves, determine the stellar mass and radius from any sources. Here I'm compiling a table of the stellar parameters from the NASA exoplanet archive, adding the stellar data from spectroscopy (Muirhead et al. 2013) and luminosities from Gaia, and using ph.fit_isochrone_lum() to fit stellar isochrones to these data. The mass, mass error, radius, and radius error of the fit isochrones will produce my mass + radius distributions which I will use to determine the stellar density distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sheilasagear/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: TableReplaceWarning: converted column 'r_result_flag' from integer to float\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/sheilasagear/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: TableReplaceWarning: converted column 'r_modality_flag' from integer to float\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/sheilasagear/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: TableReplaceWarning: converted column 'teff_err1' from integer to float\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/sheilasagear/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: TableReplaceWarning: converted column 'teff_err2' from integer to float\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "muirhead_data = pd.read_csv(\"datafiles/Muirhead2013_isochrones/muirhead_data_no_missing_data.txt\", sep=\" \")\n",
    "\n",
    "# ALL Kepler planets from exo archive\n",
    "planets = pd.read_csv('datafiles/exoplanetarchive/cumulative_kois.csv')\n",
    "\n",
    "# Take the Kepler planet archive entries for the planets in Muirhead et al. 2013 sample\n",
    "spectplanets = planets[planets['kepid'].isin(list(muirhead_data['KIC']))]\n",
    "spectplanets = spectplanets.reset_index()\n",
    "\n",
    "# Kepler-Gaia Data\n",
    "kpgaia = Table.read('datafiles/Kepler-Gaia/kepler_dr2_4arcsec.fits', format='fits').to_pandas();\n",
    "\n",
    "# Kepler-Gaia data for only the objects in our sample\n",
    "muirhead_gaia = kpgaia[kpgaia['kepid'].isin(list(muirhead_data.KIC))]\n",
    "muirhead_gaia = muirhead_gaia.reset_index()\n",
    "muirhead_gaia.rename(columns={\"index\": \"KIC\"})\n",
    "\n",
    "# Combined spectroscopy data + Gaia/Kepler data for our sample\n",
    "muirhead_comb = pd.concat([muirhead_data, muirhead_gaia], axis=1)\n",
    "muirhead_comb_nn = muirhead_comb[muirhead_comb.KOI.notnull()]\n",
    "\n",
    "# Only targets from table above with published luminosities from Gaia\n",
    "muirhead_comb_lums = muirhead_comb_nn[muirhead_comb_nn.lum_val.notnull()]\n",
    "\n",
    "# Read in MESA isochrones\n",
    "isochrones = pd.read_csv('datafiles/Muirhead2013_isochrones/isochrones_sdss_spitzer_lowmass.dat', sep='\\s\\s+', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline for Sensitivity Test\n",
    "\n",
    "1. Define \"test planet\" parameters. These parameters will come from a real Kepler planet, but I'll use a fake light curve. These \"test planet\" parameters will stay the same across the entire test.\n",
    "2. Write two functions: one that wraps the entire light curve initialization process, and one that wraps the transit fit and eccentricity estimation.\n",
    "3. For each eccentricity recovered, take the difference between the input e and the peak of the e distribution as the error.\n",
    "4. Plot on a heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a \"test planet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kepler ID for Kepler-1582 b\n",
    "kepid = 5868793\n",
    "kepname = spectplanets.loc[spectplanets['kepid'] == kepid].kepler_name.values[0]\n",
    "\n",
    "kp1582b = muirhead_comb.loc[muirhead_comb['KIC'] == kepid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 449194/738479 [00:19<00:33, 8713.64it/s] "
     ]
    }
   ],
   "source": [
    "# ph.fit_isochrone_lum() steps through all MESA isochrones and matches the ones that fit the given parameters\n",
    "iso_lums = ph.fit_isochrone_lum(kp1582b, muirhead_comb, isochrones, gaia_lum=True)\n",
    "\n",
    "# Write to csv, then read back in (keeps python notebook from crashing)\n",
    "iso_lums.to_csv(\"datafiles/isochrones/iso_lums_\" + str(kepid) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isodf = pd.read_csv(\"datafiles/isochrones/iso_lums_\" + str(kepid) + \".csv\")\n",
    "\n",
    "mstar = isodf[\"mstar\"].mean()\n",
    "mstar_err = isodf[\"mstar\"].std()\n",
    "\n",
    "rstar = isodf[\"radius\"].mean()\n",
    "rstar_err = isodf[\"radius\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_star, mass, radius = ph.find_density_dist_symmetric(mstar, mstar_err, rstar, rstar_err, arrlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rho_star, bins=20)\n",
    "plt.xlabel(\"Stellar Density [kg m^-3]\", fontsize=25)\n",
    "plt.title(\"Stellar Density (KIC 5868793) [kg m^-3]\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period, period_uerr, period_lerr, rprs, rprs_uerr, rprs_lerr, a_arc, a_uerr_arc, a_lerr_arc, i, e_arc, w_arc = ph.planet_params_from_archive(spectplanets, kepname)\n",
    "\n",
    "# We calculate a_rs to ensure that it's consistent with the spec/Gaia stellar density.\n",
    "a_rs = ph.calc_a(period*86400.0, mstar*smass_kg, rstar*srad_m)\n",
    "a_rs_err = np.mean((a_uerr_arc, a_lerr_arc))\n",
    "\n",
    "print('Stellar mass (Msun): ', mstar, 'Stellar radius (Rsun): ', rstar)\n",
    "print('Period (Days): ', period, 'Rp/Rs: ', rprs)\n",
    "print('a/Rs: ', a_rs)\n",
    "print('i (deg): ', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate A_rs prior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdist = np.random.normal(period, np.mean((abs(period_uerr), abs(period_lerr))), len(rhos_gaia))\n",
    "\n",
    "a_rs_gaia = ph.get_a_rs(rhos_gaia, pdist)\n",
    "a_rs_gaia_sigmin, a_rs_gaia_sigpls = ph.get_sigmas(a_rs_gaia)\n",
    "\n",
    "a_rs_guess = np.mean(a_rs_gaia)\n",
    "\n",
    "#a/Rs priors to put in transit fitting\n",
    "a_rs_priors = [a_rs_guess-10*np.std(a_rs_gaia), a_rs_guess+10*np.std(a_rs_gaia)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using photo_init and photo_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e and w drawn randomly from unifrom distribution\n",
    "\n",
    "n = 10\n",
    "\n",
    "e_rand = np.random.uniform(0.0, 1.0, size=n)\n",
    "w_rand = np.random.uniform(-90.0, 90.0, size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize arrays w zeros\n",
    "\n",
    "gmeans = np.zeros(n)\n",
    "gsigs = np.zeros(n)\n",
    "es_best = np.zeros(n)\n",
    "ws_best = np.zeros(n)\n",
    "zscores = np.zeros((n, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell measures (e,w) for n synthetic transits. All transits assume the exact same system (both stellar and planet parameters), except for e and w. Here I am simulating Kepler-1582b over and over with different (e,w) each time, and seeing if photoeccentric recovers the correct values.\n",
    "\n",
    "`zscores` is a list of length 2. Index 0 is the zscore of the fit eccentricity compared to the true eccentricity. Index 1 is the zscore of the fit w compared to the true w. This isn't a good way to do this but ehhh idk yet\n",
    "\n",
    "`direct` needs to be set as the directory where you want plots to be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Period (Days): ', period)\n",
    "print('Rp/Rs: ', rprs)\n",
    "print('a/Rs: ', a_rs)\n",
    "print('i (deg): ', i)\n",
    "\n",
    "for j in range(n):\n",
    "    print('e: ', e_rand[j], 'w: ', w_rand[j])\n",
    "    \n",
    "    dr = 'e_' + str(e_rand[j]) + '_w_' + str(w_rand[j])\n",
    "    direct = 'plots/' + dr + '/'\n",
    "    \n",
    "    if not os.path.exists(direct):\n",
    "        os.mkdir(direct)\n",
    "    \n",
    "    ttime = np.linspace(-24, 24, 10000)\n",
    "    tflux, tflux_err = ph.photo_init(ttime, period, rprs, a_rs, e_rand[j], i, w_rand[j], noise=0.00005)\n",
    "\n",
    "    # nsteps kept 1000, nwalkers 32, len(result) 32000\n",
    "    \n",
    "    guess_transit = np.array([ph.bls(ttime, tflux), 0.036066, a_rs_guess, 89.9, 90.0])\n",
    "    guess_ew = np.array([0, 0])\n",
    "    \n",
    "    beste, bestw, edist, wdist, gs, g_mean, g_sigmas, zsc = ph.photo_fit(ttime, tflux, tflux_err, guess_transit, guess_ew, rho_star, e_rand[j], w_rand[j], direct, nwalk, nsteps_d, ndiscard_d) \n",
    "    gmeans[j] = g_mean\n",
    "    gsigs[j] = np.mean(g_sigmas)\n",
    "    es_best[j] = beste\n",
    "    ws_best[j] = bestw\n",
    "    zscores[j] = np.mean(zsc)\n",
    "    print(\"Best e: \", beste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_best = np.array(es_best)\n",
    "ws_best = np.array(ws_best)\n",
    "zscores = np.array(zscores)\n",
    "\n",
    "np.savetxt('plots/results/32521_2_e_best.csv', es_best, delimiter=',')\n",
    "np.savetxt('plots/results/32521_2_w_best.csv', ws_best, delimiter=',')\n",
    "np.savetxt('plots/results/32521_2_e_rand.csv', e_rand, delimiter=',')\n",
    "np.savetxt('plots/results/32521_2_w_rand.csv', w_rand, delimiter=',')\n",
    "np.savetxt('plots/results/32521_2_zscores_e.csv', abs(zscores[:,0]), delimiter=',')\n",
    "np.savetxt('plots/results/32521_2_zscores_w.csv', abs(zscores[:,1]), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(e_rand, w_rand, c=zscores[:,0])\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.ylim(-90., 90.)\n",
    "plt.xlabel('True e')\n",
    "plt.ylabel('True w')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color corresponds to e error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
